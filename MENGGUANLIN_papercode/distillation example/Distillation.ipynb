{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9619d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional\n",
    "from torch import nn\n",
    "\n",
    "from labml import experiment, tracker\n",
    "from labml.configs import option\n",
    "from labml_helpers.train_valid import BatchIndex\n",
    "from labml_nn.distillation.large import LargeModel\n",
    "from labml_nn.distillation.small import SmallModel\n",
    "from labml_nn.experiments.cifar10 import CIFAR10Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c7b70f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configs(CIFAR10Configs):\n",
    "    model: SmallModel\n",
    "    large: LargeModel\n",
    "    kl_div_loss = nn.KLDivLoss(log_target=True)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    temperature: float = 5.\n",
    "    soft_targets_weight: float = 100.\n",
    "    label_loss_weight: float = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5102719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(self, batch: any, batch_idx: BatchIndex):\n",
    "    self.model.train(self.mode.is_train)\n",
    "    self.large.eval()\n",
    "    data, target = batch[0].to(self.device), batch[1].to(self.device)\n",
    "    if self.mode.is_train:\n",
    "        tracker.add_global_step(len(data))\n",
    "    with torch.no_grad():\n",
    "        large_logits = self.large(data)\n",
    "    output = self.model(data)\n",
    "    soft_targets = nn.functional.log_softmax(large_logits / self.temperature, dim=-1)\n",
    "    soft_prob = nn.functional.log_softmax(output / self.temperature, dim=-1)\n",
    "    soft_targets_loss = self.kl_div_loss(soft_prob, soft_targets)\n",
    "    label_loss = self.loss_func(output, target)\n",
    "    loss = self.soft_targets_weight * soft_targets_loss + self.label_loss_weight * label_loss\n",
    "    tracker.add({\"loss.kl_div.\": soft_targets_loss,\n",
    "                 \"loss.nll\": label_loss,\n",
    "                 \"loss.\": loss})\n",
    "    self.accuracy(output, target)\n",
    "    self.accuracy.track()\n",
    "    if self.mode.is_train:\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        if batch_idx.is_last:\n",
    "            tracker.add('model', self.model)\n",
    "        self.optimizer.zero_grad()\n",
    "    tracker.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "642a5a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@option(Configs.large)\n",
    "def _large_model(c: Configs):\n",
    "    return LargeModel().to(c.device)\n",
    "@option(Configs.model)\n",
    "def _small_student_model(c: Configs):\n",
    "    return SmallModel().to(c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11af2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_saved_model(run_uuid: str, checkpoint: int):\n",
    "    from labml_nn.distillation.large import Configs as LargeConfigs\n",
    "    experiment.evaluate()\n",
    "    conf = LargeConfigs()\n",
    "    experiment.configs(conf, experiment.load_configs(run_uuid))\n",
    "    experiment.add_pytorch_models({'model': conf.model})\n",
    "    experiment.load(run_uuid, checkpoint)\n",
    "    experiment.start()\n",
    "    return conf.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef0b4a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(run_uuid: str, checkpoint: int):\n",
    "    large_model = get_saved_model(run_uuid, checkpoint)\n",
    "    experiment.create(name='distillation', comment='cifar10')\n",
    "    conf = Configs()\n",
    "    conf.large = large_model\n",
    "    experiment.configs(conf, {\n",
    "        'optimizer.optimizer': 'Adam',\n",
    "        'optimizer.learning_rate': 2.5e-4,\n",
    "        'model': '_small_student_model',\n",
    "    })\n",
    "    experiment.add_pytorch_models({'model': conf.model})\n",
    "    experiment.load(None, None)\n",
    "    with experiment.start():\n",
    "        conf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c0929de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\"><span style=\"color: #C5C1B4\"></span>\n",
       "<span style=\"color: #C5C1B4\">--------------------------------------------------</span><span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>\n",
       "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\">LABML WARNING</span></strong></span>\n",
       "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span><strong>.labml.yaml</strong> config file could not be found. Looking in path: <span style=\"color: #208FFB\">/Users/jianyiyang/Desktop/work/deepLearning/summerClass/final/distillation example</span><span style=\"color: #C5C1B4\"></span>\n",
       "<span style=\"color: #C5C1B4\">--------------------------------------------------</span>\n",
       "<span style=\"color: #C5C1B4\"></span>\n",
       "<span style=\"color: #C5C1B4\">--------------------------------------------------</span><span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>\n",
       "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\">LABML WARNING</span></strong></span>\n",
       "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>Not a valid git repository: <strong>/Users/jianyiyang/Desktop/work/deepLearning/summerClass/final/distillation example</strong><span style=\"color: #C5C1B4\"></span>\n",
       "<span style=\"color: #C5C1B4\">--------------------------------------------------</span>\n",
       "<span style=\"color: #C5C1B4\"></span>\n",
       "<span style=\"color: #C5C1B4\">--------------------------------------------------</span><span style=\"color: #E75C58\"><strong><span style=\"text-decoration: underline\"></span></strong></span>\n",
       "<span style=\"color: #E75C58\"><strong><span style=\"text-decoration: underline\">LABML ERROR</span></strong></span>\n",
       "<span style=\"color: #E75C58\"><strong><span style=\"text-decoration: underline\"></span></strong></span>Couldn't find a previous run to load configurations: <strong>d46cd53edaec11eb93c38d6538aee7d6</strong><span style=\"color: #C5C1B4\"></span>\n",
       "<span style=\"color: #C5C1B4\">--------------------------------------------------</span>\n",
       "\n",
       "Prepare model...\n",
       "  Prepare device.device...\n",
       "    Prepare device.device_info<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t2.69ms</span>\n",
       "  Prepare device.device<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t6.46ms</span>\n",
       "Prepare model<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t110.67ms</span>\n",
       "Couldn't find a previous run\n",
       "\n",
       "<strong><span style=\"text-decoration: underline\">Notebook Experiment</span></strong>: <span style=\"color: #208FFB\">83b07f462d4311ee9310acde48001122</span>\n",
       "[clean]: <strong><span style=\"color: #DDB62B\">\"\"</span></strong>\n",
       "<span style=\"color: #C5C1B4\"></span>\n",
       "<span style=\"color: #C5C1B4\">--------------------------------------------------</span><span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>\n",
       "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\">LABML WARNING</span></strong></span>\n",
       "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>Not a valid git repository: <strong>/Users/jianyiyang/Desktop/work/deepLearning/summerClass/final/distillation example</strong><span style=\"color: #C5C1B4\"></span>\n",
       "<span style=\"color: #C5C1B4\">--------------------------------------------------</span>\n",
       "\n",
       "Prepare model<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t10.28ms</span>\n",
       "<strong><span style=\"color: #DDB62B\">No labml server url specified. Please start a labml server and specify the URL. Docs: https://github.com/labmlai/labml/tree/master/app</span></strong>\n",
       "\n",
       "<strong><span style=\"text-decoration: underline\">distillation</span></strong>: <span style=\"color: #208FFB\">83f598e22d4311ee9310acde48001122</span>\n",
       "\t<strong><span style=\"color: #DDB62B\">cifar10</span></strong>\n",
       "[clean]: <strong><span style=\"color: #DDB62B\">\"\"</span></strong>\n",
       "<strong>~/labml/configs.yaml</strong> does not exist. Creating <span style=\"color: #208FFB\">/Users/jianyiyang/.labml/configs.yaml</span>\n",
       "Initialize...\n",
       "  Prepare mode<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t3.25ms</span>\n",
       "Initialize<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t77.61ms</span>\n",
       "Prepare validator...\n",
       "  Prepare valid_loader...\n",
       "    Prepare valid_dataset...\n",
       "      Prepare dataset_transforms<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t3.33ms</span>\n",
       "    Prepare valid_dataset<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t63,081.73ms</span>\n",
       "  Prepare valid_loader<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t63,177.20ms</span>\n",
       "Prepare validator<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t63,277.03ms</span>\n",
       "Prepare trainer...\n",
       "  Prepare train_loader...\n",
       "    Prepare train_dataset<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t725.73ms</span>\n",
       "  Prepare train_loader<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t819.43ms</span>\n",
       "Prepare trainer<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t846.29ms</span>\n",
       "Prepare training_loop...\n",
       "  Prepare loop_count<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t46.19ms</span>\n",
       "Prepare training_loop<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t229.86ms</span>\n",
       "<strong><span style=\"color: #DDB62B\">       0:  </span></strong>Train:<span style=\"color: #C5C1B4\">  ...</span><span style=\"color: #208FFB\">  0ms  </span>  <span style=\"color: #208FFB\">0ms</span><span style=\"color: #D160C4\">  0:00m/  0:00m  </span>\n",
       "Prepare optimizer<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t3.94ms</span>\n",
       "Prepare optimizer.optimizer...\n",
       "  Prepare optimizer.weight_decay_obj<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t4.14ms</span>\n",
       "Prepare optimizer.optimizer<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t10.60ms</span>\n",
       "<strong><span style=\"color: #DDB62B\">  50,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 245,426ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 11,634ms  </span> loss.train: <span style=\"color: #C5C1B4\">1.051353</span> accuracy.train: <span style=\"color: #C5C1B4\">0.578660</span> loss.valid: <span style=\"color: #C5C1B4\"> 0.91503</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.608100</span>  <span style=\"color: #208FFB\">321,307ms</span><span style=\"color: #D160C4\">  0:05m/  0:48m  </span>\n",
       "<strong><span style=\"color: #DDB62B\"> 100,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 233,280ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 11,383ms  </span> loss.train: <span style=\"color: #C5C1B4\">0.858824</span> accuracy.train: <span style=\"color: #C5C1B4\">0.730740</span> loss.valid: <span style=\"color: #C5C1B4\">0.738977</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.725500</span>  <span style=\"color: #208FFB\">284,795ms</span><span style=\"color: #D160C4\">  0:09m/  0:37m  </span>\n",
       "<strong><span style=\"color: #DDB62B\"> 150,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">   241,689ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 11,771ms  </span> loss.train: <span style=\"color: #C5C1B4\">0.730364</span> accuracy.train: <span style=\"color: #C5C1B4\">0.791420</span> loss.valid: <span style=\"color: #C5C1B4\">0.676379</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.765300</span>  <span style=\"color: #208FFB\">275,545ms</span><span style=\"color: #D160C4\">  0:14m/  0:31m  </span>\n",
       "<strong><span style=\"color: #DDB62B\"> 200,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">   244,112ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 11,960ms  </span> loss.train: <span style=\"color: #C5C1B4\">0.626952</span> accuracy.train: <span style=\"color: #C5C1B4\">0.831400</span> loss.valid: <span style=\"color: #C5C1B4\">0.656888</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.774500</span>  <span style=\"color: #208FFB\">279,666ms</span><span style=\"color: #D160C4\">  0:18m/  0:27m  </span>\n",
       "<strong><span style=\"color: #DDB62B\"> 250,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">   392,136ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 15,118ms  </span> loss.train: <span style=\"color: #C5C1B4\">0.272719</span> accuracy.train: <span style=\"color: #C5C1B4\">0.865840</span> loss.valid: <span style=\"color: #C5C1B4\">0.684196</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.785900</span>  <span style=\"color: #208FFB\">304,412ms</span><span style=\"color: #D160C4\">  0:24m/  0:26m  </span>\n",
       "<strong><span style=\"color: #DDB62B\"> 300,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">   338,520ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 13,535ms  </span> loss.train: <span style=\"color: #C5C1B4\">0.121643</span> accuracy.train: <span style=\"color: #C5C1B4\">0.897300</span> loss.valid: <span style=\"color: #C5C1B4\">0.671173</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.791400</span>  <span style=\"color: #208FFB\">330,315ms</span><span style=\"color: #D160C4\">  0:30m/  0:24m  </span>\n",
       "<strong><span style=\"color: #DDB62B\"> 350,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">   312,880ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 13,134ms  </span> loss.train: <span style=\"color: #C5C1B4\">0.031197</span> accuracy.train: <span style=\"color: #C5C1B4\">0.922080</span> loss.valid: <span style=\"color: #C5C1B4\">0.658405</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.793400</span>  <span style=\"color: #208FFB\">324,037ms</span><span style=\"color: #D160C4\">  0:35m/  0:18m  </span>\n",
       "<strong><span style=\"color: #DDB62B\"> 400,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">   344,714ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 13,458ms  </span> loss.train: <span style=\"color: #C5C1B4\">0.328620</span> accuracy.train: <span style=\"color: #C5C1B4\">0.939320</span> loss.valid: <span style=\"color: #C5C1B4\">0.737392</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.792600</span>  <span style=\"color: #208FFB\">338,564ms</span><span style=\"color: #D160C4\">  0:41m/  0:14m  </span>\n",
       "<strong><span style=\"color: #DDB62B\"> 450,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">   270,469ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 11,885ms  </span> loss.train: <span style=\"color: #C5C1B4\">0.240720</span> accuracy.train: <span style=\"color: #C5C1B4\">0.952920</span> loss.valid: <span style=\"color: #C5C1B4\">0.776116</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.794700</span>  <span style=\"color: #208FFB\">335,637ms</span><span style=\"color: #D160C4\">  0:47m/  0:08m  </span>\n",
       "<strong><span style=\"color: #DDB62B\"> 500,000:  </span></strong> loss.train: <span style=\"color: #C5C1B4\">0.073790</span> accuracy.train: <span style=\"color: #C5C1B4\">0.963500</span> loss.valid: <span style=\"color: #C5C1B4\">0.805189</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.796100</span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 20:37:34.349372: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /Users/jianyiyang/Desktop/work/deepLearning/summerClass/final/distillation example/data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 170498071/170498071 [00:55<00:00, 3099570.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/jianyiyang/Desktop/work/deepLearning/summerClass/final/distillation example/data/cifar-10-python.tar.gz to /Users/jianyiyang/Desktop/work/deepLearning/summerClass/final/distillation example/data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "main('d46cd53edaec11eb93c38d6538aee7d6', 1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afea34d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LargeModel(\n",
      "  (layers): Sequential(\n",
      "    (0): Dropout(p=0.1, inplace=False)\n",
      "    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): BatchNorm()\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Dropout(p=0.1, inplace=False)\n",
      "    (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): BatchNorm()\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Dropout(p=0.1, inplace=False)\n",
      "    (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm()\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Dropout(p=0.1, inplace=False)\n",
      "    (14): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm()\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (18): Dropout(p=0.1, inplace=False)\n",
      "    (19): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): BatchNorm()\n",
      "    (21): ReLU(inplace=True)\n",
      "    (22): Dropout(p=0.1, inplace=False)\n",
      "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): BatchNorm()\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Dropout(p=0.1, inplace=False)\n",
      "    (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm()\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (31): Dropout(p=0.1, inplace=False)\n",
      "    (32): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): BatchNorm()\n",
      "    (34): ReLU(inplace=True)\n",
      "    (35): Dropout(p=0.1, inplace=False)\n",
      "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (37): BatchNorm()\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): Dropout(p=0.1, inplace=False)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm()\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (44): Dropout(p=0.1, inplace=False)\n",
      "    (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (46): BatchNorm()\n",
      "    (47): ReLU(inplace=True)\n",
      "    (48): Dropout(p=0.1, inplace=False)\n",
      "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (50): BatchNorm()\n",
      "    (51): ReLU(inplace=True)\n",
      "    (52): Dropout(p=0.1, inplace=False)\n",
      "    (53): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (54): BatchNorm()\n",
      "    (55): ReLU(inplace=True)\n",
      "    (56): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(LargeModel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9a0acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
